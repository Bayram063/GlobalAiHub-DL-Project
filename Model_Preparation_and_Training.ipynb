{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VobthrfW-2i_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "spectrogram_path = \"/content/gdrive/MyDrive/spectrograms\"\n",
        "print(os.listdir(spectrogram_path))"
      ],
      "metadata": {
        "id": "i4RbRbosF_mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/gdrive/MyDrive/data.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "Z8pTj4otsG0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "model = Sequential()\n",
        "input_shape= (128,128,1)\n",
        "\n",
        "model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape,padding='same'))\n",
        "model.add(MaxPooling2D((4, 2), strides=(4, 2),padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(48, (5, 5), padding=\"same\"))\n",
        "model.add(MaxPooling2D((4, 2), strides=(4, 2),padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(48, (5, 5), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eOtgWYMvsnGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train_len = int(len(df[\"X_train\"])/(128*128))\n",
        "Y_train_len = int(len(df[\"Y_train\"])/(128*128))\n",
        "print(\"ne\",df[\"Y_train\"].to_numpy().shape,Y_train_len)\n",
        "X_train = np.reshape(df[\"X_train\"].to_numpy(),(X_train_len,128,128,1))\n",
        "Y_train =df[\"Y_train\"].to_numpy()[:Y_train_len]\n",
        "\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\n",
        "callback=[ReduceLROnPlateau(patience=1, verbose=1),\n",
        "          ModelCheckpoint(filepath=\"/content/gdrive/MyDrive/Nicegroup_DL_Project.h5\", monitor='loss', verbose=1, save_best_only=True)]\n",
        "\n",
        "#compile\n",
        "model.compile(optimizer=\"Adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "\n",
        "#train\n",
        "print('training started.... please wait!')\n",
        "result = model.fit(x=X_train, y=Y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=1, \n",
        "                    verbose=0,\n",
        "                    # validation_data= (X_val, y_val), \n",
        "                    callbacks=callback)\n",
        "# print('training finished')"
      ],
      "metadata": {
        "id": "MbsjdCCqsn4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "pretrain_model = load_model(\"/content/gdrive/MyDrive/Nicegroup_DL_Project.h5\")\n",
        "pretrain_model.summary()\n"
      ],
      "metadata": {
        "id": "dRYowCdPz1oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "audio_path = \"/content/gdrive/MyDrive/UrbanSound8K/audio/fold1/54858-3-1-2.wav\"\n",
        "audiodata, samplerate = librosa.load(audio_path)\n",
        "spec = librosa.feature.melspectrogram(y=audiodata)\n",
        "spec_conv = librosa.amplitude_to_db(spec,ref=np.max)\n"
      ],
      "metadata": {
        "id": "VDRe6XK-z5Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spec_conv.shape)\n",
        "class_names = [indis for indis in range(0,10)]\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "cv2.imwrite(\"/content/gdrive/MyDrive/bak.jpg\",spec_conv)\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(\"/content/gdrive/MyDrive/bak.jpg\",color_mode=\"grayscale\",target_size=(128,128))\n",
        "image = np.expand_dims(image,axis=0)\n",
        "image = np.array(image)\n",
        "print(\"image.shape\",image.shape)\n",
        "cikti = pretrain_model.predict(image)\n",
        "print(\"cikti\",cikti,len(cikti[0]))\n",
        "predict_index = np.argmax(cikti)\n",
        "print(predict_index,class_names[predict_index])\n"
      ],
      "metadata": {
        "id": "Yjl6HqJjz_JD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}